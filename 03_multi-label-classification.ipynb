{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Preprocesses the data and modelled the given using the multi-label classification (A text can be two/more than two classes at same time)\n",
    "- Linear models worked well on this dataset, Logistic with OnevsRest Classifier gave the best results with multi-label accuarcy around 60%.\n",
    "- Tried Bert for multi-label classification, but it seems to struck at local minima and accuarcy is struck at multi-label accuracy 26%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sample_Submission.csv': '/kaggle/input/Sample_Submission.csv',\n",
       " 'train.csv': '/kaggle/input/train.csv',\n",
       " 'test.csv': '/kaggle/input/test.csv'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "path_dict = {}\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        path_dict[filename] = os.path.join(dirname, filename)\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "path_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5959, 3), (2553, 2))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(path_dict['train.csv'])\n",
    "test_df = pd.read_csv(path_dict['test.csv'])\n",
    "pred_df = test_df.copy()\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Review Title'] = train_df['Review Title'] + ' '\n",
    "train_df['text'] = 3*train_df['Review Title'] + train_df['Review Text']\n",
    "\n",
    "test_df['Review Title'] = test_df['Review Title'] + ' '\n",
    "test_df['text'] = 3*test_df['Review Title'] + test_df['Review Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total combinations of multi-labels in the train using the 21 classes: 431\n"
     ]
    }
   ],
   "source": [
    "train_multi_label = train_df.groupby('text')['topic'].apply(lambda x: '|'.join(x)).reset_index()\n",
    "print('Total combinations of multi-labels in the train using the 21 classes:', \n",
    "      len(train_multi_label['topic'].value_counts().to_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_multi_label = test_df.groupby('text').count().reset_index()\n",
    "test_multi_label['review_count'] = test_multi_label['Review Text']\n",
    "test_multi_label = test_multi_label[['text', 'review_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4217, 2), (1776, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_multi_label.shape, test_multi_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "364059ee214044859e1544b51475541b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c357235f3fa54ebbb7828ecc3b84287b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4217), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb66eb701934bddace1b2e8e215ff6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1776), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff7ace2a6d24112ad4b351f743b2b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2553), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "tqdm_notebook().pandas()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    from nltk.corpus import stopwords\n",
    "    stopwords = set(stopwords.words('english'))\n",
    "\n",
    "    sent = decontracted(text)\n",
    "    sent = sent.replace('\\\\r', ' ')\n",
    "    sent = sent.replace('\\\\\"', ' ')\n",
    "    sent = sent.replace('\\\\n', ' ')\n",
    "    sent = re.sub('[^A-Za-z0-9:]+', ' ', sent)\n",
    "    # https://gist.github.com/sebleier/554280\n",
    "    \n",
    "    words = sent.split(' ')\n",
    "    words = [word.lower() for word in words]\n",
    "    sent = ' '.join(e for e in words if e not in stopwords)\n",
    "    return sent.lower().strip()\n",
    "\n",
    "train_multi_label['text'] = train_multi_label['text'].progress_apply(lambda x: preprocess_text(x))\n",
    "test_multi_label['text'] = test_multi_label['text'].progress_apply(lambda x: preprocess_text(x))\n",
    "test_df['text'] = test_df['text'].progress_apply(lambda x: preprocess_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, (4217, 1), (4217, 21))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_val = train_multi_label[['text']].copy()\n",
    "from sklearn.preprocessing import LabelEncoder,MultiLabelBinarizer\n",
    "lb = MultiLabelBinarizer()\n",
    "y_train_val = lb.fit_transform(train_multi_label['topic'].apply(lambda x:x.split('|')))\n",
    "num_classes = len(lb.classes_)\n",
    "num_classes, X_train_val.shape, y_train_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MaxAbsScaler, MinMaxScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV, ShuffleSplit\n",
    "from sklearn.metrics import f1_score\n",
    "from time import time\n",
    "import scipy\n",
    "\n",
    "def build_model_pipeline(model):\n",
    "    \n",
    "    ## categorical features and ## numerical features\n",
    "    # nontext_pipe = get_nontext_pipeline()\n",
    "    \n",
    "    # text_pipes\n",
    "    text_vect1 = TfidfVectorizer(ngram_range = (1,2), min_df = 1, max_df=0.95, \n",
    "                                 norm =\"l1\")\n",
    "    text1 = make_column_transformer((text_vect1, 'text'))\n",
    "    \n",
    "    text_vect2 = TfidfVectorizer(ngram_range = (1,5), min_df = 1, max_df=0.95, \n",
    "                                 analyzer=\"char\", norm =\"l1\")\n",
    "    text2 = make_column_transformer((text_vect2, 'text'))\n",
    "    \n",
    "    \n",
    "    # feature union\n",
    "    feature_pipe = FeatureUnion(transformer_list = [('text_feat1', text1), ('text_feat2', text2)])\n",
    "    \n",
    "    classification_pipeline = Pipeline(steps = [('feat_union', feature_pipe), ('model', model)])\n",
    "    print('done! model pipeline ready...')\n",
    "    \n",
    "    return classification_pipeline\n",
    "\n",
    "\n",
    "\n",
    "def random_search(model_pipeline, param, X, y, cv = 3, search_iter = 10,):\n",
    "    \n",
    "    grid_search = RandomizedSearchCV(model_pipeline, param, scoring = 'accuracy', n_jobs=-1,\n",
    "                                     n_iter = search_iter, \n",
    "                                     cv = cv, verbose=1)\n",
    "    t0 = time()\n",
    "    grid_search = grid_search.fit(X, y)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "    print(\"Best acc: %0.4f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(param.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done! model pipeline ready...\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 211.628s\n",
      "\n",
      "Best acc: 0.4842\n",
      "Best parameters set:\n",
      "\tmodel__estimator__alpha: 1e-05\n"
     ]
    }
   ],
   "source": [
    "sgd_log = OneVsRestClassifier(SGDClassifier(loss='log', n_jobs = -1, penalty = 'l1'))\n",
    "parameters = {'model__estimator__alpha': [0.00001, 0.00005, 0.00007, 0.00009, 0.0001, 0.0007, 0.0005, 0.001, 0.005,\n",
    "                                   0.01, 0.05, 0.1, 0.5,1,10,100,1000,10000]}\n",
    "sgd_pipeline = build_model_pipeline(model = sgd_log)\n",
    "\n",
    "best_sgd_log_model = random_search(sgd_pipeline, parameters, X_train_val, y_train_val,\n",
    "                                   cv = 3, search_iter = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done! model pipeline ready...\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:  4.4min finished\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 330.433s\n",
      "\n",
      "Best acc: 0.5784\n",
      "Best parameters set:\n",
      "\tmodel__estimator__C: 1000\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "model = OneVsRestClassifier(LogisticRegression(penalty='l1', \n",
    "                                               class_weight = 'balanced'))\n",
    "parameters = {'model__estimator__C': [0.00001, 0.00005, 0.00007, 0.00009, 0.0001, 0.0007, 0.0005, 0.001, 0.005,\n",
    "                                   0.01, 0.05, 0.1, 0.5,1,10,100,1000,10000]}\n",
    "logistic_pipeline = build_model_pipeline(model = model)\n",
    "best_logistic_model = random_search(logistic_pipeline, parameters, X_train_val, y_train_val,\n",
    "                                   cv = 3, search_iter = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_multi_label[['text']].copy()\n",
    "y_test_preds = best_logistic_model.predict(X_test)\n",
    "y_test_probas = best_logistic_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_labels = lb.inverse_transform(y_test_probas > 0.1)\n",
    "test_predictions = ['|'.join(pr) for pr in y_test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_6_predictions = []\n",
    "for proba in y_test_probas:\n",
    "    top_6_predictions.append(lb.classes_[np.argsort(proba)[-6:]])  # from back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_row_preds = []\n",
    "for count, prediction in zip(test_multi_label['review_count'].values, top_6_predictions):\n",
    "    row_prediction = '|'.join(prediction[-count:])\n",
    "    test_row_preds.append(row_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(test_multi_label):\n",
    "    df1 = test_multi_label.merge(test_multi_label.topics.str.split('|',expand=True),\n",
    "                    left_index=True, right_index=True, how='outer')\n",
    "    df1.drop('topics',axis=1,inplace=True)\n",
    "    df2 = df1.melt(['text'], value_vars = [0, 1, 2, 3, 4, 5])\n",
    "    res_df = df2[df2['value'].isin(lb.classes_)]\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x brand prime delivery made huge mess x brand ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Shipment and delivery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x brand problem x brand problem x brand proble...</td>\n",
       "      <td>0</td>\n",
       "      <td>Wrong Product received</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10 price increase 35 45 within last purchase 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Effective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>really liked awhile order set pill organizer n...</td>\n",
       "      <td>0</td>\n",
       "      <td>Bad Taste/Flavor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0 0 0 taste gross</td>\n",
       "      <td>0</td>\n",
       "      <td>Bad Taste/Flavor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text variable  \\\n",
       "0  x brand prime delivery made huge mess x brand ...        0   \n",
       "1  x brand problem x brand problem x brand proble...        0   \n",
       "2  10 price increase 35 45 within last purchase 1...        0   \n",
       "3  really liked awhile order set pill organizer n...        0   \n",
       "4                                  0 0 0 taste gross        0   \n",
       "\n",
       "                    value  \n",
       "0   Shipment and delivery  \n",
       "1  Wrong Product received  \n",
       "2           Not Effective  \n",
       "3        Bad Taste/Flavor  \n",
       "4        Bad Taste/Flavor  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_multi_label['topics'] = test_row_preds\n",
    "res_df = get_preds(test_multi_label)\n",
    "res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2553, 3), Index(['text', 'variable', 'value'], dtype='object'))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.shape, res_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_pred_df = test_df.merge(res_df[['text', 'value']], how='left', on = 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2553, 4), (2553, 3))"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_pred_df = res_pred_df.drop_duplicates().reset_index(drop = 1)\n",
    "res_pred_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>text</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I use chia seed in my protein shakes. These ta...</td>\n",
       "      <td>Bad tast</td>\n",
       "      <td>bad tast bad tast bad tast use chia seed prote...</td>\n",
       "      <td>Bad Taste/Flavor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I use chia seed in my protein shakes. These ta...</td>\n",
       "      <td>Bad tast</td>\n",
       "      <td>bad tast bad tast bad tast use chia seed prote...</td>\n",
       "      <td>Quality/Contaminated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Don’t waste your money.</td>\n",
       "      <td>No change. No results.</td>\n",
       "      <td>change results change results change results w...</td>\n",
       "      <td>Not Effective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I use the book 'Fortify Your Life' by Tieraona...</td>\n",
       "      <td>Good Vegan Choice, Poor Non Vegan Choice</td>\n",
       "      <td>good vegan choice poor non vegan choice good v...</td>\n",
       "      <td>Allergic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I use the book 'Fortify Your Life' by Tieraona...</td>\n",
       "      <td>Good Vegan Choice, Poor Non Vegan Choice</td>\n",
       "      <td>good vegan choice poor non vegan choice good v...</td>\n",
       "      <td>Ingredients</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review Text  \\\n",
       "0  I use chia seed in my protein shakes. These ta...   \n",
       "1  I use chia seed in my protein shakes. These ta...   \n",
       "2                            Don’t waste your money.   \n",
       "3  I use the book 'Fortify Your Life' by Tieraona...   \n",
       "4  I use the book 'Fortify Your Life' by Tieraona...   \n",
       "\n",
       "                                Review Title  \\\n",
       "0                                  Bad tast    \n",
       "1                                  Bad tast    \n",
       "2                    No change. No results.    \n",
       "3  Good Vegan Choice, Poor Non Vegan Choice    \n",
       "4  Good Vegan Choice, Poor Non Vegan Choice    \n",
       "\n",
       "                                                text                 value  \n",
       "0  bad tast bad tast bad tast use chia seed prote...      Bad Taste/Flavor  \n",
       "1  bad tast bad tast bad tast use chia seed prote...  Quality/Contaminated  \n",
       "2  change results change results change results w...         Not Effective  \n",
       "3  good vegan choice poor non vegan choice good v...              Allergic  \n",
       "4  good vegan choice poor non vegan choice good v...           Ingredients  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df['topic'] = res_pred_df['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2553, 3) Index(['Review Text', 'Review Title', 'topic'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Bad Taste/Flavor           538\n",
       "Quality/Contaminated       300\n",
       "Not Effective              268\n",
       "Allergic                   242\n",
       "Packaging                  212\n",
       "Texture                    182\n",
       "Shipment and delivery      159\n",
       "Customer Service            99\n",
       "Color and texture           97\n",
       "Ingredients                 89\n",
       "Too big to swallow          85\n",
       "Expiry                      70\n",
       "Smells Bad                  59\n",
       "Too Sweet                   53\n",
       "Wrong Product received      33\n",
       "Pricing                     33\n",
       "False Advertisement         16\n",
       "Inferior to competitors      9\n",
       "Didn't Like                  5\n",
       "Hard to Chew                 3\n",
       "Customer Issues              1\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pred_df.shape, pred_df.columns)\n",
    "pred_df['topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553 2553\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='4-amazon-reviews-ml.csv' target='_blank'>4-amazon-reviews-ml.csv</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/4-amazon-reviews-ml.csv"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '4-amazon-reviews-ml.csv'\n",
    "print(len(test_df), len(pred_df))\n",
    "pred_df.to_csv(filename, index = None)\n",
    "from IPython.display import FileLink\n",
    "FileLink(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for proba in y_test_probas[:5]:\n",
    "#     print(np.argsort(proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test_labels = lb.inverse_transform(y_test_preds)\n",
    "# test_predictions = ['|'.join(pr) for pr in y_test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
